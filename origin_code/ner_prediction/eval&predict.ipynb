{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "import sklearn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import random\n",
    "from transformers import BertModel,AlbertTokenizer,AutoModelForTokenClassification, TrainingArguments, Trainer,trainer_callback,DataCollatorForTokenClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support,classification_report\n",
    "import json\n",
    "import gc\n",
    "import sys\n",
    "import re\n",
    "from seqeval.metrics import accuracy_score, classification_report\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassEncoder(Class):\n",
    "    if Class == 'Capacitors':\n",
    "        return 1\n",
    "    elif Class == 'Resistors':\n",
    "        return 2\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def ClassDecoder(Class):\n",
    "    if Class == 1:\n",
    "        return 'Capacitors'\n",
    "    elif Class == 2:\n",
    "        return 'Resistors'\n",
    "    else:\n",
    "        return 'Others'\n",
    "        \n",
    "def attrEncoder(all_class_list,item_class,attr):\n",
    "    if item_class in all_class_list and attr in all_class_list[item_class]:\n",
    "        if item_class == 'Capacitors':\n",
    "            return all_class_list[item_class][attr]\n",
    "        if item_class == 'Resistors':\n",
    "            return all_class_list[item_class][attr]-10\n",
    "    if attr == '-100':\n",
    "        return -100\n",
    "    return 0\n",
    "\n",
    "def attrDecoder(item_class,attr):\n",
    "    if attr==0 or attr==-100:\n",
    "        return 'others'\n",
    "    else:\n",
    "        if item_class == 'Resistors':\n",
    "            attr+=10\n",
    "        global all_attrs_dict\n",
    "        return all_attrs_dict[attr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nerClass(torch.nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(nerClass, self).__init__()\n",
    "        self.num_labels1 = config['num_labels1']\n",
    "        self.num_labels2 = config['num_labels2']\n",
    "        self.l1 = BertModel.from_pretrained(config['model'])\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "        self.classifier1 = torch.nn.Linear(128, config['num_labels1'])\n",
    "        self.classifier2 = torch.nn.Linear(128, config['num_labels2'])\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None,classes=None,device=None):\n",
    "        output = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output[0]\n",
    "        pooler = self.dropout(hidden_state)\n",
    "        \n",
    "        mask1 = torch.eq(classes,1)\n",
    "        mask2 = torch.eq(classes,2)\n",
    "#        print('pooler[mask1].size()',pooler[mask1].size())\n",
    "#        print('pooler[mask2].size()',pooler[mask2].size())\n",
    "        output1 = self.classifier1(pooler[mask1])\n",
    "        output2 = self.classifier2(pooler[mask2])\n",
    "#         print('output1.size()',output1.size())\n",
    "#         print('output2.size()',output2.size())\n",
    "    \n",
    "        return output1,output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_sub_entities(entities):\n",
    "    \"\"\"\n",
    "    Group together the adjacent tokens with the same entity predicted.\n",
    "    Args:\n",
    "        entities (:obj:`dict`): The entities predicted by the pipeline.\n",
    "    \"\"\"\n",
    "    # Get the first entity in the entity group\n",
    "    entity = entities[0][\"entity\"]\n",
    "    scores = np.sum([entity[\"score\"] for entity in entities])\n",
    "    tokens = [entity[\"word\"] for entity in entities]\n",
    "\n",
    "    entity_group = {\n",
    "        \"pred\": entity,\n",
    "        \"score\": scores,\n",
    "        \"word\": tokenizer.convert_tokens_to_string(tokens),\n",
    "        \"subtoken_num\":len(entities),\n",
    "        \"index\":entities[0][\"index\"]\n",
    "    }\n",
    "    return entity_group\n",
    "\n",
    "def group_entities(entities):\n",
    "    \"\"\"\n",
    "    Find and group together the adjacent tokens with the same entity predicted.\n",
    "    Args:\n",
    "        entities (:obj:`dict`): The entities predicted by the pipeline.\n",
    "    \"\"\"\n",
    "\n",
    "    entity_groups = []\n",
    "    entity_group_disagg = []\n",
    "\n",
    "    if entities:\n",
    "        last_idx = len(entities)-1\n",
    "\n",
    "    for entity in entities:\n",
    "        is_last_idx = entity[\"index\"] == last_idx\n",
    "        if not entity_group_disagg:\n",
    "            entity_group_disagg += [entity]\n",
    "            if is_last_idx:\n",
    "                entity_groups += [group_sub_entities(entity_group_disagg)]\n",
    "            continue\n",
    "\n",
    "        # If the current entity is similar and adjacent to the previous entity, append it to the disaggregated entity group\n",
    "        # The split is meant to account for the \"B\" and \"I\" suffixes\n",
    "        if (entity[\"entity\"] == entity_group_disagg[-1][\"entity\"] and entity[\"index\"] == entity_group_disagg[-1][\"index\"] + 1):\n",
    "            entity_group_disagg += [entity]\n",
    "            # Group the entities at the last entity\n",
    "            if is_last_idx:\n",
    "                entity_groups += [group_sub_entities(entity_group_disagg)]\n",
    "        # If the current entity is different from the previous entity, aggregate the disaggregated entity group\n",
    "        else:\n",
    "            entity_groups += [group_sub_entities(entity_group_disagg)]\n",
    "            entity_group_disagg = [entity]\n",
    "            # If it's the last entity, add it to the entity groups\n",
    "            if is_last_idx:\n",
    "                entity_groups += [group_sub_entities(entity_group_disagg)]\n",
    "\n",
    "    return entity_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_result(entities,input_tokens):\n",
    "    #print(entities)\n",
    "    initial_pred=[]\n",
    "    for item in entities:\n",
    "        initial_pred.append(item['pred'])\n",
    "    \n",
    "    if len(input_tokens)==len(initial_pred):\n",
    "        #return dict(zip(initial_pred, input_tokens))\n",
    "        return initial_pred, input_tokens, entities\n",
    "#     else:\n",
    "#         return None,None,None\n",
    "\n",
    "    if len(input_tokens)>len(initial_pred):\n",
    "        pad_num=len(input_tokens)-len(initial_pred)\n",
    "        for i in range(pad_num):\n",
    "            initial_pred.append('others')\n",
    "        print('case1')\n",
    "        print('entities',entities)\n",
    "        print('input_tokens',input_tokens)\n",
    "        print('initial_pred',initial_pred)\n",
    "        #return dict(zip(initial_pred, input_tokens))\n",
    "        return initial_pred, input_tokens,entities\n",
    "#     else:\n",
    "#         return None,None,None\n",
    "    \n",
    "    #预测的结果多于输入的token\n",
    "    if len(input_tokens)<len(initial_pred):\n",
    "        print('case2')\n",
    "        del_num= len(initial_pred)-len(input_tokens)\n",
    "        entities.sort(key=lambda item: item['score'],reverse=True)\n",
    "        entities = entities[:-del_num]\n",
    "        entities.sort(key=lambda item: item['index'],reverse=False)\n",
    "        \n",
    "        final_pred=[]\n",
    "        for item in entities:\n",
    "            final_pred.append(item['pred'])\n",
    "        return final_pred, input_tokens,entities\n",
    "#     else:\n",
    "#         return None,None,None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_tokens,input_class):\n",
    "    \"\"\"\n",
    "        - **word** (:obj:`str`) -- The token/word classified.\n",
    "        - **score** (:obj:`float`) -- The corresponding probability for :obj:`entity`.\n",
    "        - **entity** (:obj:`str`) -- The entity predicted for that token/word.\n",
    "        - **index** (:obj:`int`, only present when ``self.grouped_entities=False``) -- The index of the\n",
    "          corresponding token in the sentence.\n",
    "    \"\"\"\n",
    "    #for sentence in inputs:\n",
    "    tokens = tokenizer(input_tokens, is_split_into_words=True,add_special_tokens=False,\n",
    "                    padding=True,truncation=False,return_tensors=\"pt\")\n",
    "    tokens['classes']=torch.tensor(input_class)\n",
    "    #print(tokens)\n",
    "    # Forward\n",
    "    with torch.no_grad():\n",
    "        ids = tokens['input_ids'].to(device, dtype = torch.long)\n",
    "        attention_mask = tokens['attention_mask'].to(device, dtype = torch.long)\n",
    "        classes = tokens['classes'].to(device, dtype = torch.long)\n",
    "\n",
    "        entities1,entities2= model(ids, attention_mask,classes,device)\n",
    "\n",
    "        if input_class==1:\n",
    "            print(1)\n",
    "            entities1 = torch.squeeze(entities1, dim=0)\n",
    "            entities1 = torch.squeeze(entities1, dim=0)\n",
    "            entities = entities1.cpu().data.numpy()\n",
    "        elif input_class==2:\n",
    "            print(2)\n",
    "            entities2 = torch.squeeze(entities2, dim=0)\n",
    "            entities2 = torch.squeeze(entities2, dim=0)\n",
    "            entities = entities2.cpu().data.numpy()\n",
    "\n",
    "        input_ids = tokens[\"input_ids\"].cpu().numpy()[0]\n",
    "\n",
    "    score = np.exp(entities) / np.exp(entities).sum(-1, keepdims=True)\n",
    "    labels_idx = score.argmax(axis=-1)\n",
    "    print('score',score.shape)\n",
    "    entities = []\n",
    "    for idx, label_idx in enumerate(labels_idx):\n",
    "        entity = {\n",
    "            \"word\": tokenizer.convert_ids_to_tokens(int(input_ids[idx])),\n",
    "            \"score\": score[idx][label_idx].item(),\n",
    "            \"entity\": attrDecoder(ClassDecoder(input_class),label_idx),\n",
    "            \"index\": idx}\n",
    "\n",
    "        entities += [entity]\n",
    "    return judge_result(group_entities(entities),input_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute(predictions, references, suffix=False):\n",
    "    report = classification_report(y_true=references, y_pred=predictions, suffix=suffix, output_dict=True)\n",
    "    report.pop(\"macro avg\")\n",
    "    report.pop(\"weighted avg\")\n",
    "    overall_score = report.pop(\"micro avg\")\n",
    "\n",
    "    scores = {\n",
    "        type_name: {\n",
    "            \"precision\": score[\"precision\"],\n",
    "            \"recall\": score[\"recall\"],\n",
    "            \"f1\": score[\"f1-score\"],\n",
    "            \"number\": score[\"support\"],\n",
    "        }\n",
    "        for type_name, score in report.items()\n",
    "    }\n",
    "    scores[\"overall_precision\"] = overall_score[\"precision\"]\n",
    "    scores[\"overall_recall\"] = overall_score[\"recall\"]\n",
    "    scores[\"overall_f1\"] = overall_score[\"f1-score\"]\n",
    "    scores[\"overall_accuracy\"] = accuracy_score(y_true=references, y_pred=predictions)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label处理\n",
    "cap_attrs = {'Capacitance':1,'SizeCode':2,'RatedDCVoltageURdc':3,'PositiveTolerance':4,'NegativeTolerance':5,'TemperatureCharacteristicsCode':6,'MfrPartNumber':7,'input class':8}\n",
    "res_attrs = {'Resistance':11,'SizeCode':12,'WorkingVoltage':13,'Tolerance':14,'RatedPowerDissipationP':15,'MfrPartNumber':16,'input class':17}\n",
    "all_class_list = {'Capacitors':cap_attrs,'Resistors':res_attrs}\n",
    "\n",
    "cap_attrs_dict = dict(zip(cap_attrs.values(), cap_attrs.keys()))\n",
    "res_attrs_dict = dict(zip(res_attrs.values(), res_attrs.keys()))\n",
    "all_attrs_dict ={**cap_attrs_dict,**res_attrs_dict}\n",
    "\n",
    "# 读取数据\n",
    "with open(r'preprocess/description_with_label.json', 'r', errors='ignore', encoding='utf-8') as f:\n",
    "    js = f.read()\n",
    "    real_data = json.loads(js, strict=False)\n",
    "#317条\n",
    "real_input=[]\n",
    "real_labels=[]\n",
    "real_classes=[]\n",
    "problem_set=[]\n",
    "for i in range(len(real_data)):\n",
    "    tmp_real_input=[]\n",
    "    tmp_real_labels=[]\n",
    "    for key,val in real_data[i].items():\n",
    "        if key not in ['description','class', 'others', 'labels','Capacitance', 'RatedDCVoltageURdc', 'PositiveTolerance', 'NegativeTolerance',\n",
    "                'Resistance', 'WorkingVoltage', 'RatedPowerDissipationP', 'Tolerance']:\n",
    "            tmp_real_input.append(val.lower())\n",
    "            if ' (User input)' in key:\n",
    "                tmp_real_labels.append(key.replace(' (User input)',''))\n",
    "            else:\n",
    "                tmp_real_labels.append(key)\n",
    "    \n",
    "    if len(tmp_real_input)==len(tmp_real_labels) and len(tmp_real_input)!=0 and len(set(tmp_real_input))==len(tmp_real_labels):\n",
    "        real_input.append(tmp_real_input)\n",
    "        real_labels.append(tmp_real_labels)\n",
    "        real_classes.append(ClassEncoder(real_data[i]['class']))\n",
    "    else:\n",
    "        problem_set.append(real_data[i])\n",
    "\n",
    "# model init\n",
    "model_checkpoint = r'C:\\Users\\coldkiller\\Desktop\\supplyframe\\ner_prediction\\model_final_albert'\n",
    "tokenizer = AlbertTokenizer.from_pretrained(model_checkpoint)\n",
    "model = torch.load(model_checkpoint+r'\\model.bin',map_location='cpu')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "score (13, 9)\n",
      "1\n",
      "score (13, 9)\n",
      "1\n",
      "score (12, 9)\n",
      "1\n",
      "score (12, 9)\n",
      "1\n",
      "score (10, 9)\n",
      "1\n",
      "score (11, 9)\n",
      "1\n",
      "score (11, 9)\n",
      "1\n",
      "score (13, 9)\n",
      "1\n",
      "score (15, 9)\n",
      "1\n",
      "score (15, 9)\n",
      "1\n",
      "score (16, 9)\n",
      "1\n",
      "score (16, 9)\n",
      "1\n",
      "score (14, 9)\n",
      "2\n",
      "score (14, 8)\n",
      "2\n",
      "score (12, 8)\n",
      "2\n",
      "score (10, 8)\n",
      "case2\n",
      "2\n",
      "score (11, 8)\n",
      "2\n",
      "score (11, 8)\n",
      "1\n",
      "score (13, 9)\n",
      "1\n",
      "score (13, 9)\n",
      "1\n",
      "score (12, 9)\n",
      "1\n",
      "score (12, 9)\n",
      "2\n",
      "score (11, 8)\n",
      "1\n",
      "score (12, 9)\n",
      "1\n",
      "score (12, 9)\n",
      "1\n",
      "score (11, 9)\n",
      "1\n",
      "score (12, 9)\n",
      "1\n",
      "score (12, 9)\n",
      "1\n",
      "score (11, 9)\n",
      "1\n",
      "score (11, 9)\n",
      "1\n",
      "score (11, 9)\n",
      "1\n",
      "score (10, 9)\n",
      "1\n",
      "score (10, 9)\n",
      "1\n",
      "score (10, 9)\n",
      "1\n",
      "score (10, 9)\n",
      "2\n",
      "score (7, 8)\n",
      "2\n",
      "score (7, 8)\n",
      "2\n",
      "score (7, 8)\n",
      "2\n",
      "score (7, 8)\n",
      "2\n",
      "score (8, 8)\n",
      "2\n",
      "score (8, 8)\n",
      "2\n",
      "score (8, 8)\n",
      "2\n",
      "score (8, 8)\n",
      "2\n",
      "score (10, 8)\n",
      "2\n",
      "score (8, 8)\n",
      "2\n",
      "score (8, 8)\n",
      "2\n",
      "score (8, 8)\n",
      "2\n",
      "score (8, 8)\n",
      "2\n",
      "score (7, 8)\n",
      "2\n",
      "score (7, 8)\n",
      "2\n",
      "score (7, 8)\n",
      "2\n",
      "score (6, 8)\n",
      "2\n",
      "score (9, 8)\n",
      "2\n",
      "score (6, 8)\n",
      "1\n",
      "score (12, 9)\n",
      "1\n",
      "score (13, 9)\n",
      "1\n",
      "score (10, 9)\n",
      "1\n",
      "score (12, 9)\n",
      "1\n",
      "score (12, 9)\n",
      "1\n",
      "score (12, 9)\n",
      "1\n",
      "score (13, 9)\n",
      "1\n",
      "score (10, 9)\n",
      "2\n",
      "score (10, 8)\n",
      "2\n",
      "score (8, 8)\n",
      "2\n",
      "score (10, 8)\n",
      "2\n",
      "score (7, 8)\n",
      "2\n",
      "score (8, 8)\n",
      "2\n",
      "score (8, 8)\n",
      "2\n",
      "score (8, 8)\n",
      "2\n",
      "score (10, 8)\n",
      "2\n",
      "score (19, 8)\n",
      "case2\n",
      "2\n",
      "score (19, 8)\n",
      "case2\n",
      "2\n",
      "score (19, 8)\n",
      "case2\n",
      "2\n",
      "score (19, 8)\n",
      "case2\n",
      "2\n",
      "score (19, 8)\n",
      "case2\n",
      "2\n",
      "score (19, 8)\n",
      "case2\n",
      "2\n",
      "score (19, 8)\n",
      "2\n",
      "score (19, 8)\n",
      "case2\n",
      "2\n",
      "score (19, 8)\n",
      "case2\n",
      "2\n",
      "score (19, 8)\n",
      "case2\n",
      "2\n",
      "score (19, 8)\n",
      "case2\n",
      "2\n",
      "score (20, 8)\n",
      "case2\n",
      "2\n",
      "score (21, 8)\n",
      "case2\n",
      "2\n",
      "score (19, 8)\n",
      "case2\n",
      "2\n",
      "score (19, 8)\n",
      "case2\n",
      "2\n",
      "score (21, 8)\n",
      "2\n",
      "score (21, 8)\n",
      "2\n",
      "score (21, 8)\n",
      "case2\n",
      "2\n",
      "score (21, 8)\n",
      "case2\n",
      "2\n",
      "score (21, 8)\n",
      "case2\n",
      "2\n",
      "score (19, 8)\n",
      "1\n",
      "score (14, 9)\n",
      "1\n",
      "score (18, 9)\n",
      "1\n",
      "score (10, 9)\n",
      "1\n",
      "score (19, 9)\n",
      "1\n",
      "score (19, 9)\n",
      "1\n",
      "score (18, 9)\n",
      "1\n",
      "score (24, 9)\n",
      "1\n",
      "score (8, 9)\n",
      "1\n",
      "score (19, 9)\n",
      "2\n",
      "score (19, 8)\n",
      "2\n",
      "score (20, 8)\n",
      "2\n",
      "score (18, 8)\n",
      "2\n",
      "score (17, 8)\n",
      "case2\n",
      "2\n",
      "score (18, 8)\n",
      "case2\n",
      "2\n",
      "score (17, 8)\n",
      "case2\n",
      "2\n",
      "score (16, 8)\n",
      "2\n",
      "score (16, 8)\n",
      "2\n",
      "score (17, 8)\n",
      "2\n",
      "score (19, 8)\n",
      "2\n",
      "score (12, 8)\n",
      "2\n",
      "score (14, 8)\n",
      "2\n",
      "score (17, 8)\n",
      "case2\n",
      "2\n",
      "score (17, 8)\n",
      "case2\n",
      "2\n",
      "score (16, 8)\n",
      "2\n",
      "score (19, 8)\n",
      "case2\n",
      "2\n",
      "score (20, 8)\n",
      "case2\n",
      "2\n",
      "score (17, 8)\n",
      "case2\n",
      "2\n",
      "score (18, 8)\n",
      "case2\n",
      "2\n",
      "score (19, 8)\n",
      "case2\n",
      "2\n",
      "score (17, 8)\n",
      "case2\n",
      "2\n",
      "score (19, 8)\n",
      "case2\n",
      "2\n",
      "score (19, 8)\n",
      "2\n",
      "score (19, 8)\n",
      "case2\n",
      "2\n",
      "score (18, 8)\n",
      "2\n",
      "score (13, 8)\n",
      "2\n",
      "score (18, 8)\n",
      "2\n",
      "score (12, 8)\n",
      "case1\n",
      "entities [{'pred': 'input class', 'score': 1.0, 'word': 'res', 'subtoken_num': 1, 'index': 0}, {'pred': 'SizeCode', 'score': 3.0, 'word': '0805', 'subtoken_num': 3, 'index': 1}, {'pred': 'RatedPowerDissipationP', 'score': 3.0, 'word': '1/8w', 'subtoken_num': 3, 'index': 4}, {'pred': 'Tolerance', 'score': 4.999943196773529, 'word': '5% 4.7', 'subtoken_num': 5, 'index': 7}]\n",
      "input_tokens ['res', '0805', '1/8w', '5%', '4.7']\n",
      "initial_pred ['input class', 'SizeCode', 'RatedPowerDissipationP', 'Tolerance', 'others']\n",
      "2\n",
      "score (18, 8)\n",
      "case2\n",
      "2\n",
      "score (17, 8)\n",
      "case2\n",
      "2\n",
      "score (19, 8)\n",
      "case2\n",
      "2\n",
      "score (17, 8)\n",
      "case2\n",
      "2\n",
      "score (18, 8)\n",
      "2\n",
      "score (19, 8)\n",
      "case2\n",
      "2\n",
      "score (7, 8)\n",
      "1\n",
      "score (15, 9)\n",
      "1\n",
      "score (15, 9)\n",
      "1\n",
      "score (12, 9)\n",
      "1\n",
      "score (11, 9)\n",
      "1\n",
      "score (11, 9)\n",
      "2\n",
      "score (12, 8)\n",
      "1\n",
      "score (12, 9)\n",
      "1\n",
      "score (14, 9)\n",
      "1\n",
      "score (14, 9)\n",
      "2\n",
      "score (12, 8)\n",
      "2\n",
      "score (11, 8)\n",
      "1\n",
      "score (10, 9)\n",
      "1\n",
      "score (5, 9)\n",
      "1\n",
      "score (5, 9)\n",
      "1\n",
      "score (9, 9)\n",
      "1\n",
      "score (10, 9)\n",
      "1\n",
      "score (7, 9)\n",
      "2\n",
      "score (4, 8)\n",
      "2\n",
      "score (11, 8)\n",
      "2\n",
      "score (10, 8)\n",
      "case2\n",
      "2\n",
      "score (9, 8)\n",
      "2\n",
      "score (15, 8)\n",
      "2\n",
      "score (8, 8)\n",
      "2\n",
      "score (9, 8)\n",
      "2\n",
      "score (8, 8)\n",
      "2\n",
      "score (9, 8)\n",
      "2\n",
      "score (11, 8)\n",
      "case2\n",
      "2\n",
      "score (9, 8)\n",
      "2\n",
      "score (10, 8)\n",
      "case2\n",
      "2\n",
      "score (7, 8)\n",
      "2\n",
      "score (7, 8)\n",
      "2\n",
      "score (12, 8)\n",
      "2\n",
      "score (10, 8)\n",
      "case2\n",
      "2\n",
      "score (8, 8)\n",
      "2\n",
      "score (11, 8)\n",
      "2\n",
      "score (7, 8)\n",
      "2\n",
      "score (7, 8)\n",
      "2\n",
      "score (11, 8)\n",
      "case2\n",
      "2\n",
      "score (9, 8)\n",
      "2\n",
      "score (10, 8)\n",
      "case2\n",
      "2\n",
      "score (9, 8)\n",
      "case1\n",
      "entities [{'pred': 'SizeCode', 'score': 4.9999993443489075, 'word': '1206 r1206', 'subtoken_num': 5, 'index': 0}, {'pred': 'Resistance', 'score': 1.999996840953827, 'word': '0r', 'subtoken_num': 2, 'index': 5}, {'pred': 'Tolerance', 'score': 2.0, 'word': '5%', 'subtoken_num': 2, 'index': 7}]\n",
      "input_tokens ['1206', 'r1206', '0r', '5%']\n",
      "initial_pred ['SizeCode', 'Resistance', 'Tolerance', 'others']\n",
      "2\n",
      "score (7, 8)\n",
      "2\n",
      "score (9, 8)\n",
      "2\n",
      "score (8, 8)\n",
      "2\n",
      "score (9, 8)\n",
      "2\n",
      "score (9, 8)\n",
      "2\n",
      "score (10, 8)\n",
      "case1\n",
      "entities [{'pred': 'SizeCode', 'score': 2.9999996423721313, 'word': 'r0603', 'subtoken_num': 3, 'index': 0}, {'pred': 'Resistance', 'score': 4.753715634346008, 'word': '200r* 200r', 'subtoken_num': 5, 'index': 3}, {'pred': 'Tolerance', 'score': 1.9999999403953552, 'word': '5%', 'subtoken_num': 2, 'index': 8}]\n",
      "input_tokens ['r0603', '200r*', '200r', '5%']\n",
      "initial_pred ['SizeCode', 'Resistance', 'Tolerance', 'others']\n",
      "2\n",
      "score (15, 8)\n",
      "case2\n",
      "2\n",
      "score (16, 8)\n",
      "1\n",
      "score (12, 9)\n",
      "1\n",
      "score (14, 9)\n",
      "1\n",
      "score (14, 9)\n",
      "1\n",
      "score (12, 9)\n",
      "1\n",
      "score (10, 9)\n",
      "1\n",
      "score (11, 9)\n",
      "1\n",
      "score (13, 9)\n",
      "1\n",
      "score (16, 9)\n",
      "1\n",
      "score (24, 9)\n",
      "1\n",
      "score (10, 9)\n",
      "1\n",
      "score (10, 9)\n",
      "1\n",
      "score (13, 9)\n",
      "2\n",
      "score (11, 8)\n",
      "2\n",
      "score (11, 8)\n",
      "2\n",
      "score (13, 8)\n",
      "case2\n",
      "2\n",
      "score (13, 8)\n",
      "case2\n",
      "2\n",
      "score (11, 8)\n",
      "2\n",
      "score (12, 8)\n",
      "2\n",
      "score (12, 8)\n",
      "2\n",
      "score (12, 8)\n",
      "2\n",
      "score (11, 8)\n",
      "2\n",
      "score (12, 8)\n",
      "2\n",
      "score (11, 8)\n",
      "2\n",
      "score (13, 8)\n",
      "2\n",
      "score (9, 8)\n",
      "2\n",
      "score (19, 8)\n",
      "2\n",
      "score (9, 8)\n",
      "2\n",
      "score (13, 8)\n",
      "case2\n",
      "1\n",
      "score (10, 9)\n",
      "1\n",
      "score (10, 9)\n",
      "1\n",
      "score (10, 9)\n",
      "2\n",
      "score (5, 8)\n",
      "1\n",
      "score (9, 9)\n",
      "2\n",
      "score (11, 8)\n",
      "2\n",
      "score (11, 8)\n",
      "2\n",
      "score (11, 8)\n",
      "2\n",
      "score (13, 8)\n",
      "2\n",
      "score (11, 8)\n",
      "1\n",
      "score (12, 9)\n",
      "1\n",
      "score (8, 9)\n",
      "2\n",
      "score (10, 8)\n",
      "1\n",
      "score (7, 9)\n",
      "2\n",
      "score (10, 8)\n",
      "1\n",
      "score (10, 9)\n",
      "2\n",
      "score (13, 8)\n",
      "2\n",
      "score (10, 8)\n",
      "2\n",
      "score (11, 8)\n",
      "2\n",
      "score (11, 8)\n",
      "2\n",
      "score (13, 8)\n",
      "2\n",
      "score (11, 8)\n",
      "2\n",
      "score (13, 8)\n",
      "2\n",
      "score (11, 8)\n",
      "2\n",
      "score (10, 8)\n",
      "2\n",
      "score (11, 8)\n",
      "2\n",
      "score (11, 8)\n",
      "2\n",
      "score (11, 8)\n",
      "2\n",
      "score (11, 8)\n",
      "2\n",
      "score (10, 8)\n",
      "2\n",
      "score (10, 8)\n",
      "case2\n",
      "2\n",
      "score (9, 8)\n",
      "case2\n",
      "2\n",
      "score (7, 8)\n",
      "case2\n",
      "2\n",
      "score (7, 8)\n",
      "2\n",
      "score (8, 8)\n",
      "case2\n",
      "2\n",
      "score (8, 8)\n",
      "case2\n",
      "2\n",
      "score (8, 8)\n",
      "case2\n",
      "2\n",
      "score (10, 8)\n",
      "case2\n",
      "2\n",
      "score (10, 8)\n",
      "case2\n",
      "2\n",
      "score (10, 8)\n",
      "case2\n",
      "2\n",
      "score (8, 8)\n",
      "case2\n",
      "2\n",
      "score (7, 8)\n",
      "case2\n",
      "1\n",
      "score (10, 9)\n",
      "1\n",
      "score (8, 9)\n",
      "1\n",
      "score (8, 9)\n",
      "1\n",
      "score (8, 9)\n",
      "2\n",
      "score (7, 8)\n",
      "1\n",
      "score (7, 9)\n",
      "1\n",
      "score (8, 9)\n",
      "1\n",
      "score (8, 9)\n",
      "1\n",
      "score (8, 9)\n",
      "1\n",
      "score (9, 9)\n",
      "2\n",
      "score (7, 8)\n",
      "2\n",
      "score (8, 8)\n",
      "2\n",
      "score (7, 8)\n",
      "2\n",
      "score (8, 8)\n",
      "2\n",
      "score (8, 8)\n",
      "2\n",
      "score (8, 8)\n",
      "1\n",
      "score (13, 9)\n",
      "1\n",
      "score (3, 9)\n",
      "1\n",
      "score (3, 9)\n",
      "1\n",
      "score (9, 9)\n",
      "1\n",
      "score (3, 9)\n",
      "1\n",
      "score (11, 9)\n",
      "1\n",
      "score (3, 9)\n",
      "case2\n",
      "1\n",
      "score (3, 9)\n",
      "case2\n",
      "1\n",
      "score (9, 9)\n",
      "1\n",
      "score (11, 9)\n",
      "1\n",
      "score (15, 9)\n",
      "1\n",
      "score (9, 9)\n",
      "1\n",
      "score (13, 9)\n",
      "1\n",
      "score (13, 9)\n",
      "1\n",
      "score (11, 9)\n",
      "1\n",
      "score (13, 9)\n",
      "1\n",
      "score (9, 9)\n",
      "1\n",
      "score (13, 9)\n",
      "1\n",
      "score (13, 9)\n",
      "1\n",
      "score (13, 9)\n",
      "case1\n",
      "entities [{'pred': 'SizeCode', 'score': 6.7953110337257385, 'word': 'c0603 c0603*', 'subtoken_num': 7, 'index': 0}, {'pred': 'Capacitance', 'score': 1.9999927282333374, 'word': '22uf', 'subtoken_num': 2, 'index': 7}, {'pred': 'RatedDCVoltageURdc', 'score': 3.999994933605194, 'word': '6.3v', 'subtoken_num': 4, 'index': 9}]\n",
      "input_tokens ['c0603', 'c0603*', '22uf', '6.3v']\n",
      "initial_pred ['SizeCode', 'Capacitance', 'RatedDCVoltageURdc', 'others']\n",
      "1\n",
      "score (12, 9)\n",
      "1\n",
      "score (11, 9)\n",
      "1\n",
      "score (11, 9)\n",
      "1\n",
      "score (13, 9)\n",
      "1\n",
      "score (11, 9)\n",
      "1\n",
      "score (11, 9)\n",
      "2\n",
      "score (5, 8)\n",
      "2\n",
      "score (7, 8)\n",
      "2\n",
      "score (5, 8)\n",
      "2\n",
      "score (8, 8)\n",
      "2\n",
      "score (7, 8)\n",
      "2\n",
      "score (11, 8)\n",
      "2\n",
      "score (9, 8)\n",
      "2\n",
      "score (9, 8)\n",
      "2\n",
      "score (7, 8)\n",
      "2\n",
      "score (9, 8)\n",
      "2\n",
      "score (8, 8)\n",
      "2\n",
      "score (8, 8)\n",
      "2\n",
      "score (7, 8)\n",
      "2\n",
      "score (9, 8)\n",
      "2\n",
      "score (12, 8)\n",
      "2\n",
      "score (7, 8)\n",
      "2\n",
      "score (9, 8)\n",
      "2\n",
      "score (9, 8)\n",
      "2\n",
      "score (7, 8)\n",
      "2\n",
      "score (7, 8)\n",
      "2\n",
      "score (9, 8)\n"
     ]
    }
   ],
   "source": [
    "# get output\n",
    "inputs=[]\n",
    "preds=[]\n",
    "labels=[]\n",
    "entity_list=[]\n",
    "for i in range(len(real_input)):\n",
    "    tmp_preds,tmp_inputs,entity = predict(real_input[i],real_classes[i])\n",
    "    if tmp_preds:\n",
    "        preds.append(tmp_preds)\n",
    "        inputs.append(tmp_inputs)\n",
    "        entity_list.append(entity)\n",
    "        labels.append(real_labels[i])\n",
    "#predict(real_input[12],real_classes[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Capacitance': {'precision': 0.9818181818181818,\n",
       "  'recall': 0.9818181818181818,\n",
       "  'f1': 0.9818181818181818,\n",
       "  'number': 110},\n",
       " 'MfrPartNumber': {'precision': 0.8762886597938144,\n",
       "  'recall': 0.8762886597938144,\n",
       "  'f1': 0.8762886597938144,\n",
       "  'number': 97},\n",
       " 'PositiveTolerance': {'precision': 1.0,\n",
       "  'recall': 0.984375,\n",
       "  'f1': 0.9921259842519685,\n",
       "  'number': 64},\n",
       " 'RatedDCVoltageURdc': {'precision': 0.9908256880733946,\n",
       "  'recall': 0.9818181818181818,\n",
       "  'f1': 0.9863013698630138,\n",
       "  'number': 110},\n",
       " 'RatedPowerDissipationP': {'precision': 0.9801980198019802,\n",
       "  'recall': 0.9801980198019802,\n",
       "  'f1': 0.9801980198019802,\n",
       "  'number': 101},\n",
       " 'Resistance': {'precision': 0.9528795811518325,\n",
       "  'recall': 0.9238578680203046,\n",
       "  'f1': 0.9381443298969072,\n",
       "  'number': 197},\n",
       " 'SizeCode': {'precision': 0.9730639730639731,\n",
       "  'recall': 0.9863481228668942,\n",
       "  'f1': 0.9796610169491526,\n",
       "  'number': 293},\n",
       " 'TemperatureCharacteristicsCode': {'precision': 1.0,\n",
       "  'recall': 0.9714285714285714,\n",
       "  'f1': 0.9855072463768115,\n",
       "  'number': 70},\n",
       " 'Tolerance': {'precision': 0.9632352941176471,\n",
       "  'recall': 0.7616279069767442,\n",
       "  'f1': 0.8506493506493505,\n",
       "  'number': 172},\n",
       " 'input class': {'precision': 0.7849462365591398,\n",
       "  'recall': 0.9798657718120806,\n",
       "  'f1': 0.8716417910447762,\n",
       "  'number': 149},\n",
       " 'others': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 0},\n",
       " 'overall_precision': 0.9383712399119589,\n",
       " 'overall_recall': 0.9383712399119589,\n",
       " 'overall_f1': 0.9383712399119589,\n",
       " 'overall_accuracy': 0.9383712399119589}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate\n",
    "compute(predictions=preds, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save result\n",
    "real_res = pd.DataFrame({\"description\":inputs,\"true_labels\":labels,\"predicted_labels\":preds,'entity_list':entity_list})\n",
    "real_res.to_csv('ner_result.csv',encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sim_transformer",
   "language": "python",
   "name": "sim_transformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
