{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sampling\n",
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "import sklearn\n",
    "import time\n",
    "import random\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments,trainer_callback\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support,classification_report\n",
    "import json\n",
    "import gc\n",
    "import sys\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_class_features = sampling.read_data(\"config/config-class-features.json\")\n",
    "config_class_name = sampling.read_data(\"config/config-class-name.json\")\n",
    "config_classinfo = sampling.read_data(\"config/config-classinfo.json\")\n",
    "config_numeric_fields = sampling.read_data(\"config/config-numeric-fields.json\")\n",
    "config_dynamic_units = sampling.read_data(\"config/config-dynamic-units.json\")\n",
    "pair_params = sampling.read_data(\"config/pair-params\")\n",
    "class_dict = {'Resistors':1,'Capacitors':2,'others':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#19个resistors的文件*18,12个capacitors的文件*29，338个others文件总共374个文件,\n",
    "def convert2str(label_list,item):\n",
    "    tmp_string = ''\n",
    "\n",
    "    shuffled_item = list(item.items())\n",
    "    random.shuffle(shuffled_item)\n",
    "    \n",
    "    text, text_sep= \"\", \"\"\n",
    "    deliminter_list = ['#', ',', '/', ';', ':', '-', '_',' ']\n",
    "    deliminter = random.sample(deliminter_list, 1)[0]\n",
    "    \n",
    "    for (key, val) in shuffled_item:\n",
    "        if key == 'category' or key == 'labels' or key == 'description':\n",
    "            continue\n",
    "        elif key == 'class':\n",
    "            label_list.append(val)\n",
    "        else:\n",
    "            if random.uniform(0, 1) > 0.1: # 90% chance to use another deliminter\n",
    "                tmp_string += str(val) + random.sample(deliminter_list, 1)[0]\n",
    "            else:\n",
    "                tmp_string += str(val) + deliminter\n",
    "                \n",
    "    output = re.sub(\"(\" + \"|\".join(deliminter_list) + \")$\", \"\", tmp_string)\n",
    "    return output\n",
    "\n",
    "def get_input_from_file(path,inputClass,data_num,text_list,label_list,file_num,train_flag):\n",
    "    with open(path,'r', encoding='utf-8') as f:\n",
    "        standard_data = json.loads(f.read())\n",
    "    print('sys.getsizeof(standard_data)',sys.getsizeof(standard_data))\n",
    "    #sample_data = random.sample(standard_data,343*data_num)\n",
    "    standard_data_length = len(standard_data)\n",
    "    print('len of standard_data:',standard_data_length)\n",
    "    \n",
    "    if train_flag:\n",
    "        lower_bound = file_num*data_num*338\n",
    "        upper_bound = min(standard_data_length,(file_num+1)*data_num*338)\n",
    "        sample_data = standard_data[lower_bound:upper_bound]\n",
    "    else:\n",
    "        upper_bound = min(standard_data_length,data_num*338)\n",
    "        sample_data = standard_data[0:upper_bound]\n",
    "        \n",
    "    del standard_data\n",
    "    gc.collect()\n",
    "    for item in sample_data:\n",
    "        text_list.append(item['description'])\n",
    "        label_list.append(inputClass)\n",
    "    return text_list,label_list\n",
    "        \n",
    "def get_input_from_sampling(input_size,train_flag,file_num):\n",
    "    \"\"\"\n",
    "    input_size: the number of items to sample\n",
    "    returns the input for simpletransformer\n",
    "    \"\"\"\n",
    "    # 读取所有catogory文件\n",
    "    path = os.getcwd()\n",
    "    files= os.listdir('./formatData') #得到文件夹下的所有文件名称\n",
    "    rs_list = []\n",
    "    \n",
    "    # input_size为1表示从每一个category抽取一个样本\n",
    "    text_list = []\n",
    "    label_list = []\n",
    "    problematic = set()\n",
    "    \n",
    "    if train_flag:\n",
    "        text_list,label_list = get_input_from_file('preprocess/standard_cap.json','Capacitors',input_size,text_list,label_list,file_num,train_flag)\n",
    "        text_list,label_list = get_input_from_file('preprocess/standard_res.json','Resistors',input_size,text_list,label_list,file_num,train_flag)\n",
    "    else:\n",
    "        text_list,label_list = get_input_from_file('preprocess/standard_cap_test.json','Capacitors',input_size,text_list,label_list,file_num,train_flag)\n",
    "        text_list,label_list = get_input_from_file('preprocess/standard_res_test.json','Resistors',input_size,text_list,label_list,file_num,train_flag)\n",
    "    \n",
    "    print('进入数据生成循环')\n",
    "    for file in files: #遍历文件夹\n",
    "        file_path = os.path.join(path, 'formatData/'+file)\n",
    "        if os.path.isfile(file_path): #判断是否是文件夹，不是文件夹才打开\n",
    "            rs = sampling.sampling(file,0.6)\n",
    "            if 'Resistors' in file:\n",
    "                continue\n",
    "\n",
    "            elif 'Capacitors' in file:\n",
    "                continue\n",
    "                        \n",
    "            else:\n",
    "                for i in range(input_size):\n",
    "                    try:\n",
    "                        item = [item for item in rs.random_sampling()][0]\n",
    "                        text_list.append(convert2str(label_list,item))\n",
    "                    except Exception as e:\n",
    "                        problematic.add(file)\n",
    "                        continue\n",
    "    \n",
    "\n",
    "    #to shuffle input\n",
    "    res=[]\n",
    "    for i in range(len(label_list)):\n",
    "        res.append((text_list[i],label_list[i]))\n",
    "    random.shuffle(res)\n",
    "    for i in range(len(label_list)):\n",
    "        text_list[i]=res[i][0]\n",
    "        label_list[i]=res[i][1]\n",
    "        \n",
    "    print('problematic',problematic)\n",
    "    print('query数量：',len(text_list))\n",
    "    print('label数量：',len(label_list))\n",
    "    print('sys.getsizeof(text_list)',sys.getsizeof(text_list))\n",
    "    print('sys.getsizeof(label_list)',sys.getsizeof(label_list))\n",
    "    \n",
    "#     with open('running_output.txt','a') as f:\n",
    "#         f.write('query数量:'+str(len(text_list))+'\\n')\n",
    "#         f.write('label数量:'+str(len(label_list))+'\\n')\n",
    "#         f.write('problematic:'+str(problematic)+'\\n')\n",
    "    return text_list,label_list\n",
    "\n",
    "# a,b=get_input_from_sampling(1,True)\n",
    "# for i in range(len(b)):\n",
    "#     print((a[i],b[i]),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #保存列表，每行一个元素\n",
    "# with open('input_example.txt','w',encoding='utf-8') as f:\n",
    "#     c=[]\n",
    "#     for i in range(len(b)):\n",
    "#         c.append(b[i]+'       '+a[i])\n",
    "#     f.write('\\n'.join(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_process(config_classinfo,model_checkpoint,train_size,class_dict,tokenizer,file_num):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    files= os.listdir('./class_inputData')\n",
    "\n",
    "#     with open('running_output.txt','w') as f:\n",
    "#         f.write(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())+'\\n')\n",
    "    \n",
    "    #准备训练数据\n",
    "    print(f'train dataset{file_num}\\n')\n",
    "    if f'train_encodings{file_num}.pt' in files and f'train_labels{file_num}.csv' in files:\n",
    "        print('read train dataset\\n')\n",
    "        train_encodings = torch.load(f'./class_inputData/train_encodings{file_num}.pt')\n",
    "        train_labels = pd.read_csv(f'./class_inputData/train_labels{file_num}.csv',index_col=0)\n",
    "        train_labels = train_labels['0'].to_list()\n",
    "    else:\n",
    "        print('generate train dataset\\n')\n",
    "        train_dataset,train_labels = get_input_from_sampling(train_size,train_flag=True,file_num=file_num)\n",
    "        train_encodings = tokenizer(train_dataset,padding=True,truncation=False)\n",
    "\n",
    "        pd.DataFrame(train_labels).to_csv(f'./class_inputData/train_labels{file_num}.csv')\n",
    "        torch.save(train_encodings, f'./class_inputData/train_encodings{file_num}.pt')\n",
    "        print('train dataset saved')\n",
    "        \n",
    "    # encode the labels\n",
    "    train_labels_encoded = list(map(lambda x:ClassEncoder(x),train_labels))\n",
    "\n",
    "    print('training dataset is ok\\n')\n",
    "    return train_encodings,train_labels_encoded\n",
    "\n",
    "def test_input_process(config_classinfo,model_checkpoint,test_size,class_dict,tokenizer):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "#    print('test dataset')\n",
    "#    files= os.listdir('./class_inputData')\n",
    "    \n",
    "#     if 'test_encodings.pt' in files and 'test_labels.csv' in files:\n",
    "#         print('read test dataset\\n')\n",
    "#         test_encodings = torch.load('./class_inputData/test_encodings.pt')\n",
    "#         test_labels = pd.read_csv('./class_inputData/test_labels.csv',index_col=0)\n",
    "#         test_labels = test_labels['0'].to_list()\n",
    "#     else:\n",
    "    print('generate test dataset\\n')\n",
    "    test_dataset,test_labels = get_input_from_sampling(test_size,train_flag=False,file_num=1)\n",
    "    test_encodings = tokenizer(test_dataset,padding=True,truncation=False)\n",
    "\n",
    "#         torch.save(test_encodings, './class_inputData/test_encodings.pt')\n",
    "#         pd.DataFrame(test_labels).to_csv('./class_inputData/test_labels.csv')\n",
    "#         print('test dataset saved\\n')\n",
    "\n",
    "    # encode the labels\n",
    "    test_labels_encoded = list(map(lambda x:ClassEncoder(x),test_labels))\n",
    "    print('testing dataset is ok\\n')\n",
    "    return test_encodings,test_labels_encoded,test_dataset[:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class processDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassEncoder(Class):\n",
    "    if Class == 'Resistors':\n",
    "        return 1\n",
    "    elif Class == 'Capacitors':\n",
    "        return 2\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def ClassDecoder(Class):\n",
    "    if Class == 1:\n",
    "        return 'Resistors'\n",
    "    elif Class == 2:\n",
    "        return 'Capacitors'\n",
    "    else:\n",
    "        return 'Others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='micro',zero_division=1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    \n",
    "    print('compute_metrics:',len(labels))\n",
    "    class_result = {'accuracy': acc,\n",
    "                'f1': f1,\n",
    "                'precision': precision,\n",
    "                'recall': recall}\n",
    "    \n",
    "#     with open('class_classification_report.json','a',errors='ignore') as f: \n",
    "#         json.dump(class_report,f,ensure_ascii=False, indent = 4) \n",
    "\n",
    "    global write_result\n",
    "    if write_result:\n",
    "        class_preds = [ClassDecoder(item) for item in preds]\n",
    "        class_labels = [ClassDecoder(item) for item in labels]\n",
    "        #class_report = classification_report(class_labels, class_preds,output_dict=True)\n",
    "        class_report = classification_report(class_labels, class_preds)\n",
    "        with open('class_classification_report.txt','a') as f: \n",
    "            f.write(class_report)\n",
    "            \n",
    "#     with open('class_running_output.txt','w') as f:\n",
    "#         f.write('class_result:'+str(class_result)+'\\n')\n",
    "\n",
    "    return class_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epoch=10,logging_steps=10,file_num=10,train_size=150,test_size=30):\n",
    "\n",
    "    set_seed(1024)\n",
    "    global write_result\n",
    "    write_result = True\n",
    "    model_checkpoint = \"albert-base-v2\"\n",
    "    #model_checkpoint = \"prajjwal1/bert-tiny\"\n",
    "    # model_checkpoint = r'C:\\Users\\coldkiller\\Desktop\\supplyframe\\checkpoint-3500'\n",
    "    \n",
    "    gpu_available = torch.cuda.is_available()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "    \n",
    "    print('torch.cuda.is_available()',gpu_available)\n",
    "    \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=3)\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./models',\n",
    "        dataloader_num_workers=7,\n",
    "        do_train = True,\n",
    "#        do_eval = True,\n",
    "#        evaluation_strategy = 'steps',\n",
    "        learning_rate=1e-5,\n",
    "        weight_decay=0.01,\n",
    "        adam_beta1=0.9,\n",
    "        adam_beta2=0.999,\n",
    "        adam_epsilon=1e-8,\n",
    "        num_train_epochs=1,\n",
    "        logging_steps=logging_steps,\n",
    "#        save_steps=10000,\n",
    "        no_cuda= not gpu_available,\n",
    "        seed=1024,\n",
    "        per_device_train_batch_size=64,\n",
    "        per_device_eval_batch_size=64,\n",
    "        warmup_steps=20,\n",
    "        logging_dir='./logs',\n",
    "        load_best_model_at_end=True,\n",
    "#        metric_for_best_model = 'eval_loss',\n",
    "#        greater_is_better = False,\n",
    "#        save_total_limit=5,\n",
    "        disable_tqdm=True)\n",
    "    \n",
    "    # read real data\n",
    "    with open(r'preprocess/description_with_label.json', 'r', errors='ignore', encoding='utf-8') as f:\n",
    "        js = f.read()\n",
    "        real_data = json.loads(js, strict=False)\n",
    "\n",
    "    real_input=[]\n",
    "    real_labels=[]\n",
    "    for i in range(len(real_data)):\n",
    "        if 'class' in real_data[i]:\n",
    "            real_input.append(real_data[i]['description'])\n",
    "            real_labels.append(ClassEncoder(real_data[i]['class']))\n",
    "\n",
    "    print('real_input',len(real_input))\n",
    "    real_encodings = tokenizer(real_input,padding=True,truncation=False)\n",
    "    real_dataset = processDataset(real_encodings,real_labels)\n",
    "\n",
    "    # training loop\n",
    "    total_time = 0\n",
    "    for j in range(num_epoch):\n",
    "        print(f'\\n\\n%%%%%%%%%%%%%%epoch{j}%%%%%%%%%%%%%%\\n\\n')\n",
    "        for i in range(file_num):\n",
    "            print(f'\\n\\nbegin generate train_dataset{i}\\n\\n')\n",
    "            train_data,train_labels_encoded = train_input_process(config_classinfo,model_checkpoint,train_size,class_dict,tokenizer,i)\n",
    "            train_dataset = processDataset(train_data, train_labels_encoded)\n",
    "\n",
    "    #         if i>0:\n",
    "    #             trainer.args.learning_rate = tmp_learning_rate\n",
    "            \n",
    "            trainer = Trainer(\n",
    "                model=model,\n",
    "                args=training_args,\n",
    "                tokenizer=tokenizer,\n",
    "                compute_metrics=compute_metrics,\n",
    "                train_dataset=train_dataset,\n",
    "                eval_dataset=real_dataset\n",
    "            )\n",
    "            # trainer.add_callback(trainer_callback.EarlyStoppingCallback(early_stopping_patience=500,early_stopping_threshold=0.0001))\n",
    "            \n",
    "            trainer.args.output_dir=f'./models/model{j}'\n",
    "            # Train the model\n",
    "            print('Training begins\\n')\n",
    "            start = time.time()\n",
    "            trainer.train()\n",
    "            end = time.time()\n",
    "            print(f\"training time: {end - start}\")\n",
    "            total_time+=(end-start)\n",
    "\n",
    "            #为下一批训练数据做初始化\n",
    "            trainer.args.warmup_steps=0\n",
    "            #tmp_learning_rate = trainer.args.learning_rate\n",
    "            gc.collect()\n",
    "    \n",
    "        # 保存模型\n",
    "        trainer.save_model()\n",
    "        \n",
    "        with open('class_classification_report.txt','a') as f: \n",
    "            f.write(f'%%%%%%%%%%epoch {j}%%%%%%%%%%%\\n')\n",
    "        real_result = trainer.predict(real_dataset)\n",
    "        print('real_result:  ',real_result.metrics)\n",
    "        with open('validation_report.txt','a') as f: \n",
    "            f.write(f'epoch {j}:{real_result.metrics}\\n')\n",
    "#     with open('albert_structure.txt','w') as f:\n",
    "#         f.write(str(trainer.model))\n",
    "\n",
    "    print('\\n\\ntotal_training_time:',total_time)\n",
    "    # generate test data\n",
    "    test_data,test_labels_encoded,sample_data = test_input_process(config_classinfo,model_checkpoint,test_size,class_dict,tokenizer)\n",
    "    test_dataset = processDataset(test_data, test_labels_encoded)\n",
    "    \n",
    "    # show result\n",
    "#     global write_result\n",
    "#     write_result = True\n",
    "    with open('class_classification_report.txt','a') as f: \n",
    "        f.write('~~~~~~~~~~training result:~~~~~~~~~~\\n')\n",
    "    train_result = trainer.predict(train_dataset).metrics\n",
    "    print('train_result:  ',train_result)\n",
    "    \n",
    "    with open('class_classification_report.txt','a') as f: \n",
    "        f.write('~~~~~~~~~~testing result:~~~~~~~~~~\\n')\n",
    "    test_result = trainer.predict(test_dataset)\n",
    "    print('test_result:  ',test_result.metrics)\n",
    "    \n",
    "    with open('class_classification_report.txt','a') as f: \n",
    "        f.write('~~~~~~~~~~validation result:~~~~~~~~~~\\n')\n",
    "    real_result = trainer.predict(real_dataset)\n",
    "    print('real_result:  ',real_result.metrics)\n",
    "    \n",
    "    # save result\n",
    "    test_preds = [ClassDecoder(item) for item in test_result.predictions.argmax(-1)[:1000]]\n",
    "    test_labels = [ClassDecoder(item) for item in test_labels_encoded[:1000]]\n",
    "    test_res = pd.DataFrame({\"description\":sample_data,\"true_labels\":test_labels,\"predicted_labels\":test_preds})\n",
    "    test_res.to_csv('test_description_result.csv',encoding='utf_8_sig')   \n",
    "    \n",
    "    real_preds = [ClassDecoder(item) for item in real_result.predictions.argmax(-1)]\n",
    "    real_labels = [ClassDecoder(item) for item in real_labels]\n",
    "    real_res = pd.DataFrame({\"description\":real_input,\"true_labels\":real_labels,\"predicted_labels\":real_preds})\n",
    "    real_res.to_csv('real_description_result.csv',encoding='utf_8_sig')\n",
    "    \n",
    "#     with open('running_output.txt','a') as f:\n",
    "#         f.write(f\"training time: {end - start}\"+'\\n')\n",
    "#         f.write('train_dataset'+str(train_result)+'\\n')        \n",
    "#         f.write('test_dataset'+str(test_result)+'\\n')\n",
    "        \n",
    "#     with open('real_description_output.json','w',errors='ignore') as f: \n",
    "#         json.dump(class_result,f,ensure_ascii=False, indent = 4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_available() False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real_input 404\n",
      "\n",
      "\n",
      "%%%%%%%%%%%%%%epoch0%%%%%%%%%%%%%%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "begin generate train_dataset0\n",
      "\n",
      "\n",
      "train dataset\n",
      "\n",
      "generate train dataset\n",
      "\n",
      "sys.getsizeof(standard_data) 7984\n",
      "len of standard_data: 969\n",
      "sys.getsizeof(standard_data) 9024\n",
      "len of standard_data: 1000\n",
      "进入数据生成循环\n",
      "problematic set()\n",
      "query数量： 214\n",
      "label数量： 214\n",
      "sys.getsizeof(text_list) 1928\n",
      "sys.getsizeof(label_list) 1928\n",
      "train dataset saved\n",
      "training dataset is ok\n",
      "\n",
      "Training begins\n",
      "\n",
      "{'loss': 1.1212972402572632, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.25}\n",
      "{'loss': 1.1151254177093506, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.5}\n",
      "{'loss': 1.1422961950302124, 'learning_rate': 1.5e-06, 'epoch': 0.75}\n",
      "{'loss': 1.0758541822433472, 'learning_rate': 2.0000000000000003e-06, 'epoch': 1.0}\n",
      "{'epoch': 1.0}\n",
      "training time: 1.405212640762329\n",
      "compute_metrics: 404\n",
      "real_result:   {'eval_loss': 1.1702924966812134, 'eval_accuracy': 0.05198019801980198, 'eval_f1': 0.05198019801980198, 'eval_precision': 0.05198019801980198, 'eval_recall': 0.05198019801980198}\n",
      "\n",
      "\n",
      "%%%%%%%%%%%%%%epoch1%%%%%%%%%%%%%%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "begin generate train_dataset0\n",
      "\n",
      "\n",
      "train dataset\n",
      "\n",
      "read train dataset\n",
      "\n",
      "training dataset is ok\n",
      "\n",
      "Training begins\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\sim_transformer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda\\envs\\sim_transformer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda\\envs\\sim_transformer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1208775043487549, 'learning_rate': 7.500000000000001e-06, 'epoch': 0.25}\n",
      "{'loss': 1.1135300397872925, 'learning_rate': 5e-06, 'epoch': 0.5}\n",
      "{'loss': 1.1394386291503906, 'learning_rate': 2.5e-06, 'epoch': 0.75}\n",
      "{'loss': 1.075491189956665, 'learning_rate': 0.0, 'epoch': 1.0}\n",
      "{'epoch': 1.0}\n",
      "training time: 1.4411461353302002\n",
      "compute_metrics: 404\n",
      "real_result:   {'eval_loss': 1.1641098260879517, 'eval_accuracy': 0.05693069306930693, 'eval_f1': 0.05693069306930693, 'eval_precision': 0.05693069306930693, 'eval_recall': 0.05693069306930693}\n",
      "\n",
      "\n",
      "%%%%%%%%%%%%%%epoch2%%%%%%%%%%%%%%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "begin generate train_dataset0\n",
      "\n",
      "\n",
      "train dataset\n",
      "\n",
      "read train dataset\n",
      "\n",
      "training dataset is ok\n",
      "\n",
      "Training begins\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\sim_transformer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda\\envs\\sim_transformer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda\\envs\\sim_transformer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1160757541656494, 'learning_rate': 7.500000000000001e-06, 'epoch': 0.25}\n",
      "{'loss': 1.109866738319397, 'learning_rate': 5e-06, 'epoch': 0.5}\n",
      "{'loss': 1.1355868577957153, 'learning_rate': 2.5e-06, 'epoch': 0.75}\n",
      "{'loss': 1.075109601020813, 'learning_rate': 0.0, 'epoch': 1.0}\n",
      "{'epoch': 1.0}\n",
      "training time: 1.3683388233184814\n",
      "compute_metrics: 404\n",
      "real_result:   {'eval_loss': 1.1577144861221313, 'eval_accuracy': 0.09900990099009901, 'eval_f1': 0.09900990099009901, 'eval_precision': 0.09900990099009901, 'eval_recall': 0.09900990099009901}\n",
      "\n",
      "\n",
      "total_training_time: 4.214697599411011\n",
      "generate test dataset\n",
      "\n",
      "sys.getsizeof(standard_data) 7984\n",
      "len of standard_data: 969\n",
      "sys.getsizeof(standard_data) 9024\n",
      "len of standard_data: 1000\n",
      "进入数据生成循环\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\sim_transformer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda\\envs\\sim_transformer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda\\envs\\sim_transformer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problematic set()\n",
      "query数量： 107\n",
      "label数量： 107\n",
      "sys.getsizeof(text_list) 1072\n",
      "sys.getsizeof(label_list) 1072\n",
      "testing dataset is ok\n",
      "\n",
      "compute_metrics: 214\n",
      "train_result:   {'eval_loss': 1.1102577447891235, 'eval_accuracy': 0.32710280373831774, 'eval_f1': 0.32710280373831774, 'eval_precision': 0.32710280373831774, 'eval_recall': 0.32710280373831774}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\sim_transformer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda\\envs\\sim_transformer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda\\envs\\sim_transformer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_metrics: 107\n",
      "test_result:   {'eval_loss': 1.103386402130127, 'eval_accuracy': 0.34579439252336447, 'eval_f1': 0.34579439252336447, 'eval_precision': 0.34579439252336447, 'eval_recall': 0.34579439252336447}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\sim_transformer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda\\envs\\sim_transformer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda\\envs\\sim_transformer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_metrics: 404\n",
      "real_result:   {'eval_loss': 1.1577144861221313, 'eval_accuracy': 0.09900990099009901, 'eval_f1': 0.09900990099009901, 'eval_precision': 0.09900990099009901, 'eval_recall': 0.09900990099009901}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\sim_transformer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda\\envs\\sim_transformer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda\\envs\\sim_transformer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    write_result = True\n",
    "    train(num_epoch=50,logging_steps=50,file_num=30,train_size=100,test_size=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#改比例，训练数据数量，epoch,dataloader_num_workers,模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# albert50万\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir='./results',\n",
    "#     dataloader_num_workers=7,\n",
    "#     do_train = True,\n",
    "#     learning_rate=1e-5,\n",
    "#     weight_decay=0.01,\n",
    "#     adam_beta1=0.9,\n",
    "#     adam_beta2=0.999,\n",
    "#     adam_epsilon=1e-8,\n",
    "#     num_train_epochs=10,\n",
    "#     logging_steps=10,\n",
    "#     save_steps=10000,\n",
    "#     no_cuda= not gpu_available,\n",
    "#     seed=1024,\n",
    "#     per_device_train_batch_size=64,\n",
    "#     per_device_eval_batch_size=64,\n",
    "#     warmup_steps=20,\n",
    "#     logging_dir='./logs',\n",
    "#     load_best_model_at_end=True,\n",
    "#     save_total_limit=5,\n",
    "#     disable_tqdm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALBERT150万\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir='./results',\n",
    "#     dataloader_num_workers=7,\n",
    "#     do_train = True,\n",
    "#     do_eval = True,\n",
    "#     evaluation_strategy = 'steps',\n",
    "#     learning_rate=1e-5,\n",
    "#     weight_decay=0.01,\n",
    "#     adam_beta1=0.9,\n",
    "#     adam_beta2=0.999,\n",
    "#     adam_epsilon=1e-8,\n",
    "#     num_train_epochs=num_train_epochs,\n",
    "#     logging_steps=logging_steps,\n",
    "#     save_steps=10000,\n",
    "#     no_cuda= not gpu_available,\n",
    "#     seed=1024,\n",
    "#     per_device_train_batch_size=64,\n",
    "#     per_device_eval_batch_size=64,\n",
    "#     warmup_steps=20,\n",
    "#     logging_dir='./logs',\n",
    "#     load_best_model_at_end=True,\n",
    "#     metric_for_best_model = 'eval_loss',\n",
    "#     greater_is_better = False,\n",
    "#     save_total_limit=5,\n",
    "#     disable_tqdm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bert-tiny\n",
    "# training_args = TrainingArguments(\n",
    "#         output_dir='./results',\n",
    "#         dataloader_num_workers=7,\n",
    "#         do_train = True,\n",
    "#         learning_rate=1e-5,\n",
    "#         weight_decay=0.01,\n",
    "#         adam_beta1=0.9,\n",
    "#         adam_beta2=0.999,\n",
    "#         adam_epsilon=1e-8,\n",
    "#         num_train_epochs=100,\n",
    "#         logging_steps=100,\n",
    "#         save_steps=500000,\n",
    "#         no_cuda= not gpu_available,\n",
    "#         seed=1024,\n",
    "#         per_device_train_batch_size=256,\n",
    "#         per_device_eval_batch_size=256,\n",
    "#         warmup_steps=5,\n",
    "#         logging_dir='./logs',\n",
    "#         load_best_model_at_end=True,\n",
    "#         save_total_limit=5,\n",
    "#         disable_tqdm=True\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sim_transformer",
   "language": "python",
   "name": "sim_transformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
