{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sampling\n",
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "import sklearn\n",
    "import time\n",
    "import random\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support,classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import json\n",
    "from simpletransformers.ner import NERModel,NERArgs\n",
    "import gc\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_class_features = sampling.read_data(\"config/config-class-features.json\")\n",
    "config_class_name = sampling.read_data(\"config/config-class-name.json\")\n",
    "config_classinfo = sampling.read_data(\"config/config-classinfo.json\")\n",
    "config_numeric_fields = sampling.read_data(\"config/config-numeric-fields.json\")\n",
    "config_dynamic_units = sampling.read_data(\"config/config-dynamic-units.json\")\n",
    "pair_params = sampling.read_data(\"config/pair-params\")\n",
    "class_dict = {'Resistors':1,'Capacitors':2,'others':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with open(r'samples.json', 'r', errors='ignore', encoding='utf-8') as f:\n",
    "#     js = f.read()\n",
    "#     result = json.loads(js, strict=False, encoding=\"GB2312\")\n",
    "#3737470"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "进入数据生成循环\n",
      "train_flag True\n",
      "problematic set()\n",
      "query数量： 41\n",
      "label数量： 41\n",
      "[' 50 OHM 50 OHM 2.0 SMALL OUTLINE 1.0', ' 3/5µF 165.0uV 3/5mΩ 2816 10.0% 20.85 604D', ' 6/6µF ALUMINUM (WET) POLARIZED 8/2mΩ -47.5°C 85.0°C WIRE BULK', ' Signal Circuits -13.5kV +-15 9.0V NO BIPOLAR 14 Analog Computational Functions', ' YES 0.147% 1.65µs NOT SPECIFIED 3.425 18.0 Analog to Digital Converters', ' 10.0 BIPOLAR 5.0kV 3.004 Not Qualified SQUARE', ' 5.0mV +-6 -5.5 NO 7.353mm NOT SPECIFIED -20.0°C 70.0°C 8.625mV', ' 1.0 15.5ns BIDIRECTIONAL ACT 3.25kV 15.94mm CERAMIC, METAL-SEALED COFIRED NO', ' 1.35e-06µF 12.5% CERAMIC 75.0V 105.0°C -55.0°C 1.65mm NCA', ' 0.007µF X7R 1206 CNx0AX33x;JM 1.15', ' 6.295kΩ 1206 0.75% 0.325kW 64.0ohm 16 Gold (Au)', ' 30150.0ohm 3/1% 300ppm/°C 0.388W NO WA04X RECTANGULAR PACKAGE', ' Connector Support 625.0 BACKSHELL 6/10 SQUARE SOCKET NUT 3x0SA#019B2440DD6 SIGNAL ZH SERIES CONNECTOR', ' CMOS 5.0kV 7/1 STS-1/OC-1 0.14mA RECTANGULAR T-1(DS1) ATM;SDH;SONET', ' consumer 1.0 5.001% 5/4 12.05 6.4 4.974', ' 30.0 13 2.489 1.0 RECTANGULAR Gold (Au) AU BRASS', ' DIP DUAL e0 -5.0°C 60.0°C', ' 0.087 250.0kHz 3/7kHz 9000 OHMS CT 600 OHMS CT 12.62mm 3000.0 Audio Transformers', ' 47.2GW 2.0 7/3 5.075 COMMERCIAL MATTE TIN e4 BIPOLAR', ' Signal Circuits 1/8 NO 13.5V 3.0 Tin/Lead (Sn/Pb) R-PDSO-G8', ' Trans 0.74 230 145.0uV 9/10VA 4/2', ' 6/3Ah 1.512mA SILVER OXIDE 6/2mm 52.5°C -20.0°C', ' 5.0uV 26.8 YES MILITARY 4.625 6/1 2.54mm', ' 40.0 FEMALE 2 COMMERCIAL POLARIZED HOUSING .5004', ' Trig 721.5V 210.0mA 2.0 155.0 RVS BLOCKING BOD :BR211-213 NOT SPECIFIED Trigger Devices', ' 0.14 6.5nA 20.0 4/9 UNSPECIFIED TO-269AA 4 TS 16949', ' 放大电路 -15.0V 3.5 8.0µA NO Not Qualified NO', ' 8.0 16384 80251 32.0 35.0 13.25mm Bus Controllers 0.5mm', ' 8.0 ALS 2.55V 2.5 SMALL OUTLINE, SHRINK PITCH -47.5°C 105.0°C 38535V;38534K;883S', ' 3.75 16.0 5.0 2.55 Not Qualified R-PDSO-G16 20', ' N FEMALE 14750.0MHz 1250.0MHz #6FV1x-FREQ/TBW2-TP/TP 50 OHM', ' Oscil -20.0uV 1500.0% 10.0kHz 3000.0MHz 6000.0MHz MECHANICAL TUNED CAVITY OSCILLATOR CHASSIS MOUNT', ' 2.4kV CMOS 1.0 1.0 NOT SPECIFIED PLASTIC/EPOXY S-PQCC-N16', ' 0.012µF 50.0kV CERAMIC 5.0 ,VJ12x6Y683JNXAT2M', ' 10/10µF 20.5mV X7R TR, PAPER, 7 INCH WRAPAROUND', ' 5.0 50 OHM 3/1 2400.0 PLASTIC 3 POLE; TAPE AND REEL BULK', ' 5 PPM/YEAR 9/3 4000.0ppm 0.4 CST_CC3.58Mx1-TC 80.0 -32.5', ' 245.0V LONG 60.0kV 0.65mA ROCKER THERMAL CIRCUIT BREAKER 2', ' PANEL 6 FEMALE-FEMALE ALUMINUM ALLOY NOT SPECIFIED -55.0 125.0 NO NO', ' ALUMINUM ALLOY 61 37 851 NO', ' 1.0 3.95 3-STATE FCT 3.3V 0.0°C 5/6°C YES STANDARD']\n",
      "['Filters', 'Capacitors', 'Capacitors', 'Signal Circuits', 'Converters', 'Telecommunication Circuits', 'Signal Circuits', 'Logic', 'Capacitors', 'Capacitors', 'Resistors', 'Resistors', 'Connector Support', 'Telecommunication Circuits', 'Consumer Circuits', 'Connectors', 'Consumer Circuits', 'Transformers', 'Consumer Circuits', 'Signal Circuits', 'Transformers', 'Batteries', 'Microcontrollers and Processors', 'Connectors', 'Trigger Devices', 'Diodes', 'Amplifier Circuits', 'Microcontrollers and Processors', 'Logic', 'Drivers And Interfaces', 'Filters', 'Oscillators', 'Telecommunication Circuits', 'Capacitors', 'Capacitors', 'Filters', 'Crystals/Resonators', 'Circuit Protection', 'Connectors', 'Connectors', 'Logic']\n"
     ]
    }
   ],
   "source": [
    "#19个resistors的文件,12个capacitors的文件，总共374个文件\n",
    "def convert2str(label_list,item):\n",
    "    tmp_string = ''\n",
    "\n",
    "    shuffled_item = list(item.items())\n",
    "    random.shuffle(shuffled_item)\n",
    "    for key, val in item.items():\n",
    "        if key == 'category':\n",
    "            continue\n",
    "        elif key == 'class':\n",
    "            label_list.append(val)\n",
    "        else:\n",
    "            tmp_string+=' '+str(val)\n",
    "\n",
    "    return tmp_string\n",
    "\n",
    "def get_input_from_sampling(input_size: int,train_flag:True):\n",
    "    \"\"\"\n",
    "    input_size: the number of items to sample\n",
    "    returns the input for simpletransformer\n",
    "    \"\"\"\n",
    "    # 读取所有catogory文件\n",
    "    path = os.getcwd()\n",
    "    files= os.listdir('./formatData') #得到文件夹下的所有文件名称\n",
    "    rs_list = []\n",
    "    \n",
    "    # input_size为1表示从每一个category抽取一个样本\n",
    "    text_list = []\n",
    "    label_list = []\n",
    "    problematic = set()\n",
    "    \n",
    "    print('进入数据生成循环')\n",
    "    for file in files: #遍历文件夹\n",
    "        file_path = os.path.join(path, 'formatData/'+file)\n",
    "        if os.path.isfile(file_path): #判断是否是文件夹，不是文件夹才打开\n",
    "            rs = sampling.sampling(file,0.6)\n",
    "            if 'Resistors' in file:\n",
    "                for i in range(18*input_size):\n",
    "                    try:\n",
    "                        item = [item for item in rs.random_sampling()][0]\n",
    "                        text_list.append(convert2str(label_list,item)) \n",
    "                    except Exception as e:\n",
    "                        problematic.add(rs)\n",
    "                        continue\n",
    "\n",
    "            elif 'Capacitors' in file:\n",
    "                for i in range(29*input_size):\n",
    "                    try:\n",
    "                        item = [item for item in rs.random_sampling()][0]\n",
    "                        text_list.append(convert2str(label_list,item))\n",
    "                    except Exception as e:\n",
    "                        problematic.add(rs)\n",
    "                        continue\n",
    "                        \n",
    "            else:\n",
    "                for i in range(input_size):\n",
    "                    try:\n",
    "                        item = [item for item in rs.random_sampling()][0]\n",
    "                        text_list.append(convert2str(label_list,item))\n",
    "                    except Exception as e:\n",
    "                        problematic.add(rs)\n",
    "                        continue\n",
    "    \n",
    "    print('train_flag',train_flag)\n",
    "    print('problematic',problematic)\n",
    "    print('query数量：',len(text_list))\n",
    "    print('label数量：',len(label_list))\n",
    "    \n",
    "    with open('running_output.txt','a') as f:\n",
    "        f.write('train_flag:'+str(train_flag)+'\\n')\n",
    "        f.write('query数量:'+str(len(text_list))+'\\n')\n",
    "        f.write('label数量:'+str(len(label_list))+'\\n')\n",
    "        f.write('problematic:'+str(problematic)+'\\n')\n",
    "    return text_list,label_list\n",
    "\n",
    "# a,b=get_input_from_sampling(1,True)\n",
    "# print(a)\n",
    "# print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_input_from_sampling(item_list,input_size,train_flag=True):\n",
    "#     \"\"\"\n",
    "#     input_size: the number of items to sample\n",
    "#     returns the input for simpletransformer\n",
    "#     \"\"\"\n",
    "#     random.shuffle(item_list)\n",
    "#     # input_size为1表示从每一个category抽取一个样本\n",
    "#     text_list = []\n",
    "#     label_list = []\n",
    "#     problematic = set()\n",
    "\n",
    "#     tmp_string = ''\n",
    "            \n",
    "#     shuffled_item = list(item.items())\n",
    "#     random.shuffle(shuffled_item)\n",
    "#     for item in item_list:\n",
    "#         for key, val in item.items():\n",
    "#             if key == 'category':\n",
    "\n",
    "#             elif key == 'class':\n",
    "#                 label_list.append(val)\n",
    "#                 for i in range():\n",
    "#                     item_list.append(item)\n",
    "#             else:\n",
    "#                 tmp_string+=' '+str(val)\n",
    "\n",
    "#     text_list.append(tmp_string)\n",
    "    \n",
    "#     print('train_flag',train_flag)\n",
    "#     print('problematic',problematic)\n",
    "#     print('query数量：',len(text_list))\n",
    "#     print('label数量：',len(label_list))\n",
    "    \n",
    "#     with open('running_output.txt','a') as f:\n",
    "#         f.write('train_flag:'+str(train_flag)+'\\n')\n",
    "#         f.write('query数量:'+str(len(text_list))+'\\n')\n",
    "#         f.write('label数量:'+str(len(label_list))+'\\n')\n",
    "#         f.write('problematic:'+str(problematic)+'\\n')\n",
    "#     return text_list,label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432\n",
      "进入循环\n",
      "train_flag True\n",
      "problematic set()\n",
      "query数量： 37\n",
      "label数量： 37\n",
      "[' 18 STRAIGHT BOARD 0.65 0.02 RECTANGULAR 2 NO', ' SMT 3.0% METAL GLAZE/THICK FILM 16525.5MΩ 0.163uW res ISOLATED', ' 8/8 150.0 NO DIFFUSED ZENER IN GATE REGION 228.5mV 654.0mV', ' 1.0 2.785mm 5 BIDIRECTIONAL 5.0mV', ' 5/9 CMOS 3.4V 10/10 28', ' +-15 -9.0 -15.0kV -19.0 NO Analog Computational Functions', ' xAX23_87EGC OFFSET BINARY 2/5 HTSON 3 4.0uV 1.0 1.0', ' 10/6% 5.5kHz 4/8MHz 1/7MHz -20.0mV MECHANICAL TUNED CAVITY OSCILLATOR Oscillators 6/4 -20.0', ' SPEECH SYNTHESIZER 65.0°C Audio Synthesizer ICs 5/5°C Consumer Circuits DUAL TSOP1', ' 3/3 33.3 15.913 NOT SPECIFIED 12.0 5.397 NO', ' L20XB12XH11 (mm) 7.75 1.6 2400.0 10/4', ' 225.0kHz 1.5 GENERAL PURPOSE AUDIO TRANSFORMER e0 16 OHMS MIL-PRF-27/172E 500.5 5/4kHz Transformers', ' PANEL RECEPTACLE-RECEPTACLE FEMALE-MALE ALUMINUM ALLOY 125.0 231-104-07 16 4/6', ' 10/9°C 0.12Ah LITHIUM 2.5uV -25.0°C FLAT(+), BUTTON(-)', ' 0805 125.0°C SMT 3.5% -55.0°C 0.028µF 900.0 Silver/Palladium (Ag/Pd) CERAMIC', ' 12 NO CABLE AND PANEL PLUG DB/AS74x37-922PNF1031 37 ALUMINUM ALLOY', ' e4 STS-1/OC-1 51840.0 CMOS SMALL OUTLINE 3.3kV R-CQCC-N16', ' 2.0 SMALL OUTLINE, THIN PROFILE, SHRINK PITCH 15.1nW 1/6 14 ZIP UNSPECIFIED', ' 7/9µs 1 4/2 ADC, PROPRIETARY METHOD Analog to Digital Converters 转换器 0.234% 3/6MHz', ' 5.0 10/7e-05 MIL-19500/469 350.0mV SILICON 1.1', ' 4.0uV Signal Circuits Tin/Lead (Sn/Pb) 100.0 6/4 VOLTAGE-MODE NO Analog Waveform Generation Functions', ' FL05-0002-G 50 OHM L4.9XB3.9XH1.25 (mm)/L0.193XB0.154XH0.049 (inch) 50 OHM Tin/Lead (Sn/Pb) 2.0 3000.0', ' 放大电路 TR 30000.0µV DIP 6/8µA 2.5', ' e0 56.0 4.5 89.0 YES 5.01% GULL WING', ' 2/6MHz e4 17.284 13.0MHz 3000.0ppm 0.25 5 PPM/YEAR Ceramic Resonators L2.5XB2.0XH1.1 (mm)/L0.098XB0.079XH0.043 (inch)', ' RECTANGULAR PACKAGE 20.5kV 0.035µF THROUGH HOLE MOUNT 1206 Capacitors CERAMIC 14 SMT', ' 50 OHM 85.0°C L32.45XB12.7XH12.7 (mm)/L1.278XB0.5XH0.5 (inch) N MALE 1.5 4000.0MHz 3/3°C', ' COAX 18.0 LOCKING LOOSE 1.85 RG-178', ' 2/5 5 13.5 BICMOS 5.0 Drivers 8/8 Bus Terminators', ' 3.438 YES 225 1.405kV 11.0mm 1.522mV 8.0', ' 1155.0mA 35.0mΩ 18850.0µF TANTALUM (DRY/SOLID) 111.5V Capacitors 10/9°C 电容 85.0°C Other Cap. Values Available On Request', ' ENABLE LOW POSITIVE EDGE FCT NO LEAD 4.0 RECTANGULAR', ' 3/2 SURFACE MOUNT 115.0V Trans INPUT VOLTAGE 115 V AND OUTPUT VOLTAGE 230 V IS ALSO POSSIBLE 230', ' 13 xPx4812-0,10-445 ZINC MALE BLUE AUDIO/RCA CONNECTOR', ' 13.5V 105.0°C 13.95 -40.0°C T-A1x23x Automotive Circuits NO', ' 5.0uV NOT SPECIFIED BIDIRECTIONAL 4.0 Arithmetic Circuits', ' e4 TRIP FREE 46.0kV 240.0V NO Circuit Breaker INSTANTANEOUS 3.0nA']\n",
      "['Connectors', 'Resistors', 'Trigger Devices', 'Logic', 'Telecommunication Circuits', 'Signal Circuits', 'Telecommunication Circuits', 'Oscillators', 'Consumer Circuits', 'Microcontrollers and Processors', 'Filters', 'Transformers', 'Connectors', 'Batteries', 'Capacitors', 'Connectors', 'Telecommunication Circuits', 'Consumer Circuits', 'Converters', 'Diodes', 'Signal Circuits', 'Filters', 'Amplifier Circuits', 'Consumer Circuits', 'Crystals/Resonators', 'Capacitors', 'Filters', 'Connector Support', 'Drivers And Interfaces', 'Microcontrollers and Processors', 'Capacitors', 'Logic', 'Transformers', 'Connectors', 'Signal Circuits', 'Logic', 'Circuit Protection']\n"
     ]
    }
   ],
   "source": [
    "# #19个resistors的文件,12个capacitors的文件，总共374个文件\n",
    "# def get_rs_list_of_all_category():\n",
    "#     \"\"\"\n",
    "#     input_size: the number of items to sample\n",
    "#     returns the input for simpletransformer\n",
    "#     \"\"\"\n",
    "#     # 读取所有catogory文件\n",
    "#     path = os.getcwd()\n",
    "#     files= os.listdir('./formatData') #得到文件夹下的所有文件名称\n",
    "#     rs_list = []\n",
    "    \n",
    "    \n",
    "#     for file in files: #遍历文件夹\n",
    "#         file_path = os.path.join(path, 'formatData/'+file)\n",
    "#         if os.path.isfile(file_path): #判断是否是文件夹，不是文件夹才打开\n",
    "#             if 'Resistors' in file:\n",
    "#                 for i in range(19):\n",
    "#                     rs = sampling.sampling(file,0.6)\n",
    "#                     rs_list.append((rs,file))\n",
    "#             elif 'Capacitors' in file:\n",
    "#                 for i in range(28):\n",
    "#                     rs = sampling.sampling(file,0.6)\n",
    "#                     rs_list.append((rs,file))\n",
    "#             else:\n",
    "#                 rs = sampling.sampling(file,0.6)\n",
    "#                 rs_list.append((rs,file))\n",
    "    \n",
    "#     random.shuffle(rs_list)        \n",
    "#     return rs_list\n",
    "\n",
    "# def get_input_from_sampling(input_size: int,train_flag:True):\n",
    "#     \"\"\"\n",
    "#     input_size: the number of items to sample\n",
    "#     returns the input for simpletransformer\n",
    "#     \"\"\"\n",
    "#     rs_list = get_rs_list_of_all_category()\n",
    "    \n",
    "#     print('sys.getsizeof(rs_list)',sys.getsizeof(rs_list))\n",
    "    \n",
    "#     # input_size为1表示从每一个category抽取一个样本\n",
    "#     text_list = []\n",
    "#     label_list = []\n",
    "#     problematic = set()\n",
    "    \n",
    "#     #print(rs_list)\n",
    "#     print('进入数据生成循环')\n",
    "#     for i in range(input_size):\n",
    "#         for rs in rs_list:\n",
    "#             try:\n",
    "#                 item = [item for item in rs[0].random_sampling()][0]\n",
    "#             except Exception as e:\n",
    "#                 problematic.add(rs[1])\n",
    "#                 continue\n",
    "                \n",
    "# #             # 保存抽样数据\n",
    "# #             if i<5 and train_flag:\n",
    "# #                 with open('input_saved.json','a',errors='ignore') as f: \n",
    "# # #                    f.write(json.dumps(data, ensure_ascii=False))\n",
    "# #                     json.dump(item,f,ensure_ascii=False, indent = 4)\n",
    "# #                     #f.write(js)\n",
    "            \n",
    "#             tmp_string = ''\n",
    "            \n",
    "# #             shuffled_item = list(item.items())\n",
    "# #             random.shuffle(shuffled_item)\n",
    "#             for key, val in item.items():\n",
    "#                 if key == 'category':\n",
    "#                     continue\n",
    "#                 elif key == 'class':\n",
    "#                     label_list.append(val)\n",
    "#                 else:\n",
    "#                     tmp_string+=' '+str(val)\n",
    "\n",
    "#             text_list.append(tmp_string)\n",
    "    \n",
    "#     print('train_flag',train_flag)\n",
    "#     print('problematic',problematic)\n",
    "#     print('query数量：',len(text_list))\n",
    "#     print('label数量：',len(label_list))\n",
    "    \n",
    "#     with open('running_output.txt','a') as f:\n",
    "#         f.write('train_flag:'+str(train_flag)+'\\n')\n",
    "#         f.write('query数量:'+str(len(text_list))+'\\n')\n",
    "#         f.write('label数量:'+str(len(label_list))+'\\n')\n",
    "#         f.write('problematic:'+str(problematic)+'\\n')\n",
    "#     return text_list,label_list\n",
    "\n",
    "# # a,b=get_input_from_sampling(1,True)\n",
    "# # print(a)\n",
    "# # print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_process(config_classinfo,model_checkpoint,tokenizer,train_size,test_size,class_dict):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    print('script running\\n')\n",
    "    files= os.listdir('./class_inputData')\n",
    "\n",
    "    with open('running_output.txt','w') as f:\n",
    "        f.write(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())+'\\n')\n",
    "    \n",
    "    #准备训练数据\n",
    "    print('train dataset\\n')\n",
    "    if 'train_encodings.pt' in files and 'train_labels.csv' in files:\n",
    "        print('read train dataset\\n')\n",
    "        train_encodings = torch.load('./class_inputData/train_encodings.pt')\n",
    "        train_labels = pd.read_csv('./class_inputData/train_labels.csv',index_col=0)\n",
    "        train_labels = train_labels['0'].to_list()\n",
    "    else:\n",
    "        print('generate train dataset\\n')\n",
    "        train_dataset,train_labels = get_input_from_sampling(train_size,train_flag=True)\n",
    "        pd.DataFrame(train_dataset).to_csv('./class_inputData/train_dataset.csv')\n",
    "        print('sys.getsizeof(train_dataset)',sys.getsizeof(train_dataset))\n",
    "        \n",
    "        print('begin train tokenizer')\n",
    "        train_encodings = tokenizer(train_dataset,padding=True,truncation=True)\n",
    "        del train_dataset\n",
    "        gc.collect()\n",
    "        print('finish train tokenizer')\n",
    "        pd.DataFrame(train_labels).to_csv('./class_inputData/train_labels.csv')\n",
    "        torch.save(train_encodings, './class_inputData/train_encodings.pt')\n",
    "\n",
    "        print('train dataset saved')\n",
    "        \n",
    "    print('%%%%%%%%%%%%%%%%%%%%%%%%%%%%%')\n",
    "    \n",
    "    print('test dataset')\n",
    "    if 'test_encodings.pt' in files and 'test_labels.csv' in files:\n",
    "        print('read test dataset\\n')\n",
    "        test_encodings = torch.load('./class_inputData/test_encodings.pt')\n",
    "        test_labels = pd.read_csv('./class_inputData/test_labels.csv',index_col=0)\n",
    "        test_labels = test_labels['0'].to_list()\n",
    "    else:\n",
    "        print('generate test dataset\\n')\n",
    "        test_dataset,test_labels = get_input_from_sampling(test_size,train_flag=False)\n",
    "        pd.DataFrame(test_dataset).to_csv('./class_inputData/test_dataset.csv')\n",
    "        print('begin test tokenizer')\n",
    "        test_encodings = tokenizer(test_dataset,padding=True,truncation=True)\n",
    "        del test_dataset\n",
    "        gc.collect()\n",
    "        print('finish test tokenizer')\n",
    "        torch.save(test_encodings, './class_inputData/test_encodings.pt')\n",
    "        pd.DataFrame(test_labels).to_csv('./class_inputData/test_labels.csv')\n",
    "        print('test dataset saved\\n')\n",
    "\n",
    "    # encode the labels\n",
    "    train_labels_encoded = list(map(lambda x:ClassEncoder(x),train_labels))\n",
    "    print(len(train_labels_encoded))\n",
    "    test_labels_encoded = list(map(lambda x:ClassEncoder(x),test_labels))\n",
    "    print(len(test_labels_encoded))\n",
    "    \n",
    "    return train_encodings,test_encodings,train_labels_encoded,test_labels_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class processDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassEncoder(Class):\n",
    "    if Class == 'Resistors':\n",
    "        return 1\n",
    "    elif Class == 'Capacitors':\n",
    "        return 2\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassDecoder(Class):\n",
    "    if Class == 1:\n",
    "        return 'Resistors'\n",
    "    elif Class == 2:\n",
    "        return 'Capacitors'\n",
    "    else:\n",
    "        return 'Others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='micro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    \n",
    "    global class_dict\n",
    "    print('compute_metrics:',len(labels))\n",
    "\n",
    "    res = pd.DataFrame({\"preds\":preds,\"labels\":labels})\n",
    "    res[:1000].to_csv('test_set_result.csv')\n",
    "    \n",
    "    class_preds = [ClassDecoder(item) for item in preds]\n",
    "    class_labels = [ClassDecoder(item) for item in labels]\n",
    "    class_report = classification_report(class_labels, class_preds,output_dict=True)\n",
    "    class_report2 = classification_report(class_labels, class_preds)\n",
    "    class_result = {'accuracy': acc,\n",
    "                'f1': f1,\n",
    "                'precision': precision,\n",
    "                'recall': recall}\n",
    "    \n",
    "    with open('class_classification_report.json','w',errors='ignore') as f: \n",
    "        json.dump(class_report,f,ensure_ascii=False, indent = 4) \n",
    "#     with open('class_classification_report_string_format.txt','w') as f: \n",
    "#         f.write(class_report2)\n",
    "    with open('class_running_output.txt','w') as f:\n",
    "        f.write('class_result:'+str(class_result)+'\\n')\n",
    "\n",
    "    return class_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "\n",
    "    set_seed(1024)\n",
    "    model_checkpoint = \"albert-base-v2\"\n",
    "    # model_checkpoint = r'C:\\Users\\coldkiller\\Desktop\\supplyframe\\checkpoint-3500'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "    gpu_available = torch.cuda.is_available()\n",
    "    \n",
    "    #logging.basicConfig(level=logging.DEBUG,format='%(asctime)s %(message)s')\n",
    "    \n",
    "    print('torch.cuda.is_available()',gpu_available)\n",
    "    \n",
    "    train_encodings,test_encodings,train_labels_encoded,test_labels_encoded = input_process(config_classinfo,\n",
    "                                                                                    model_checkpoint,tokenizer,2500,250,class_dict)\n",
    "\n",
    "    print('input_process_finished\\n')\n",
    "    train_dataset = processDataset(train_encodings, train_labels_encoded)\n",
    "    test_dataset = processDataset(test_encodings, test_labels_encoded)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=3)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        learning_rate=1e-5,\n",
    "        weight_decay=0.01,\n",
    "        adam_beta1=0.9,\n",
    "        adam_beta2=0.999,\n",
    "        adam_epsilon=1e-8,\n",
    "        num_train_epochs=100,\n",
    "        logging_steps=300000,\n",
    "        save_steps=1000000,\n",
    "        no_cuda= not gpu_available,\n",
    "        seed=1024,\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=64,\n",
    "        warmup_steps=500,\n",
    "        logging_dir='./logs',\n",
    "        load_best_model_at_end=True,\n",
    "        save_total_limit=5,\n",
    "        disable_tqdm=True\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    print('Training begins\\n')\n",
    "    start = time.time()\n",
    "    trainer.train()\n",
    "    end = time.time()\n",
    "    print(f\"training time: {end - start}\")\n",
    "\n",
    "#     train_result = trainer.evaluate(train_dataset)\n",
    "#     print(train_result)\n",
    "    test_result = trainer.predict(test_dataset).metrics\n",
    "    print(test_result)\n",
    "\n",
    "    trainer.save_model()\n",
    "    with open('running_output.txt','a') as f:\n",
    "        f.write(f\"training time: {end - start}\"+'\\n')\n",
    "        f.write('train_dataset'+str(train_result)+'\\n')        \n",
    "        f.write('test_dataset'+str(test_result)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_class_mapping():\n",
    "    #加上unknown是36个class\n",
    "    class_dict = {}\n",
    "    i=1\n",
    "    for part_class in config_classinfo.keys():\n",
    "        class_dict[part_class] = i\n",
    "        i+=1\n",
    "\n",
    "    class_dict['unknown_class'] = 0\n",
    "\n",
    "    with open('class_dict.txt', 'w') as f:\n",
    "        dic = json.dumps(class_dict)  \n",
    "        f.write(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     training_args = TrainingArguments(\n",
    "#         output_dir='./results',\n",
    "#         learning_rate=1e-5,\n",
    "#         weight_decay=0.01,\n",
    "#         adam_beta1=0.9,\n",
    "#         adam_beta2=0.999,\n",
    "#         adam_epsilon=1e-8,\n",
    "#         num_train_epochs=1,\n",
    "#         logging_steps=5,\n",
    "#         evaluation_strategy='steps',\n",
    "#         save_steps=500000,\n",
    "#         no_cuda=False,\n",
    "#         seed=1024,\n",
    "#         per_device_train_batch_size=16,\n",
    "#         per_device_eval_batch_size=64,\n",
    "#         warmup_steps=500,\n",
    "#         logging_dir='./logs',\n",
    "#         load_best_model_at_end=True,\n",
    "#         save_total_limit=5,\n",
    "#         disable_tqdm=True\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sim_transformer",
   "language": "python",
   "name": "sim_transformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
